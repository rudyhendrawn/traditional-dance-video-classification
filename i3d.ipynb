{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudyhendrawn/traditional-dance-video-classification/blob/main/i3d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ee5fa18",
      "metadata": {
        "id": "9ee5fa18"
      },
      "outputs": [],
      "source": [
        "!rm -rfv sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f8f11cd",
      "metadata": {
        "id": "8f8f11cd"
      },
      "source": [
        "### Mounting Repository\n",
        "\n",
        "Mount the repository to get all the data (directories and utilities files) ready to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3eb99b6f",
      "metadata": {
        "id": "3eb99b6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "550c5954-09d2-43f6-c1ef-4b7fe9e23219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'traditional-dance-video-classification'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 184 (delta 58), reused 66 (delta 16), pack-reused 47\u001b[K\n",
            "Receiving objects: 100% (184/184), 127.21 MiB | 26.52 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "mv: cannot move 'traditional-dance-video-classification/checkpoint' to './checkpoint': Directory not empty\n",
            "mv: cannot move 'traditional-dance-video-classification/dataset' to './dataset': Directory not empty\n",
            "mv: cannot move 'traditional-dance-video-classification/history' to './history': Directory not empty\n",
            "mv: cannot move 'traditional-dance-video-classification/img' to './img': Directory not empty\n",
            "mv: cannot move 'traditional-dance-video-classification/lib' to './lib': Directory not empty\n",
            "mv: cannot move 'traditional-dance-video-classification/misc' to './misc': Directory not empty\n",
            "mv: cannot move 'traditional-dance-video-classification/notebooks' to './notebooks': Directory not empty\n",
            "removed 'traditional-dance-video-classification/history/.gitignore'\n",
            "removed directory 'traditional-dance-video-classification/history'\n",
            "removed 'traditional-dance-video-classification/misc/video-frame-converter.ipynb'\n",
            "removed 'traditional-dance-video-classification/misc/dataset-reader.ipynb'\n",
            "removed directory 'traditional-dance-video-classification/misc'\n",
            "removed 'traditional-dance-video-classification/.git/config'\n",
            "removed 'traditional-dance-video-classification/.git/description'\n",
            "removed 'traditional-dance-video-classification/.git/HEAD'\n",
            "removed 'traditional-dance-video-classification/.git/refs/heads/main'\n",
            "removed directory 'traditional-dance-video-classification/.git/refs/heads'\n",
            "removed 'traditional-dance-video-classification/.git/refs/remotes/origin/HEAD'\n",
            "removed directory 'traditional-dance-video-classification/.git/refs/remotes/origin'\n",
            "removed directory 'traditional-dance-video-classification/.git/refs/remotes'\n",
            "removed directory 'traditional-dance-video-classification/.git/refs/tags'\n",
            "removed directory 'traditional-dance-video-classification/.git/refs'\n",
            "removed 'traditional-dance-video-classification/.git/index'\n",
            "removed 'traditional-dance-video-classification/.git/hooks/pre-rebase.sample'\n",
            "removed 'traditional-dance-video-classification/.git/hooks/pre-applypatch.sample'\n",
            "removed 'traditional-dance-video-classification/.git/hooks/update.sample'\n",
            "removed 'traditional-dance-video-classification/.git/hooks/pre-receive.sample'\n",
            "removed 'traditional-dance-video-classification/.git/hooks/applypatch-msg.sample'\n",
            "removed 'traditional-dance-video-classification/.git/hooks/pre-push.sample'\n",
            "removed 'traditional-dance-video-classification/.git/hooks/post-update.sample'\n",
            "removed 'traditional-dance-video-classification/.git/hooks/commit-msg.sample'\n",
            "removed 'traditional-dance-video-classification/.git/hooks/pre-merge-commit.sample'\n",
            "removed 'traditional-dance-video-classification/.git/hooks/prepare-commit-msg.sample'\n",
            "removed 'traditional-dance-video-classification/.git/hooks/pre-commit.sample'\n",
            "removed 'traditional-dance-video-classification/.git/hooks/fsmonitor-watchman.sample'\n",
            "removed 'traditional-dance-video-classification/.git/hooks/push-to-checkout.sample'\n",
            "removed directory 'traditional-dance-video-classification/.git/hooks'\n",
            "removed 'traditional-dance-video-classification/.git/logs/HEAD'\n",
            "removed 'traditional-dance-video-classification/.git/logs/refs/heads/main'\n",
            "removed directory 'traditional-dance-video-classification/.git/logs/refs/heads'\n",
            "removed 'traditional-dance-video-classification/.git/logs/refs/remotes/origin/HEAD'\n",
            "removed directory 'traditional-dance-video-classification/.git/logs/refs/remotes/origin'\n",
            "removed directory 'traditional-dance-video-classification/.git/logs/refs/remotes'\n",
            "removed directory 'traditional-dance-video-classification/.git/logs/refs'\n",
            "removed directory 'traditional-dance-video-classification/.git/logs'\n",
            "removed 'traditional-dance-video-classification/.git/info/exclude'\n",
            "removed directory 'traditional-dance-video-classification/.git/info'\n",
            "removed 'traditional-dance-video-classification/.git/objects/pack/pack-eb9a2369ac826968c3fc5ddd6003f5105eab7c3f.pack'\n",
            "removed 'traditional-dance-video-classification/.git/objects/pack/pack-eb9a2369ac826968c3fc5ddd6003f5105eab7c3f.idx'\n",
            "removed directory 'traditional-dance-video-classification/.git/objects/pack'\n",
            "removed directory 'traditional-dance-video-classification/.git/objects/info'\n",
            "removed directory 'traditional-dance-video-classification/.git/objects'\n",
            "removed directory 'traditional-dance-video-classification/.git/branches'\n",
            "removed 'traditional-dance-video-classification/.git/packed-refs'\n",
            "removed directory 'traditional-dance-video-classification/.git'\n",
            "removed 'traditional-dance-video-classification/img/example-left-2.png'\n",
            "removed 'traditional-dance-video-classification/img/example-front-2.png'\n",
            "removed 'traditional-dance-video-classification/img/example-front-1.png'\n",
            "removed 'traditional-dance-video-classification/img/Thumbs.db'\n",
            "removed 'traditional-dance-video-classification/img/example-left-1.png'\n",
            "removed 'traditional-dance-video-classification/img/example-right-1.png'\n",
            "removed 'traditional-dance-video-classification/img/example-right-2.png'\n",
            "removed directory 'traditional-dance-video-classification/img'\n",
            "removed 'traditional-dance-video-classification/lib/helpers.py'\n",
            "removed 'traditional-dance-video-classification/lib/i3d_inception/__init__.py'\n",
            "removed 'traditional-dance-video-classification/lib/i3d_inception/main.py'\n",
            "removed directory 'traditional-dance-video-classification/lib/i3d_inception'\n",
            "removed 'traditional-dance-video-classification/lib/keras_video/generator.py'\n",
            "removed 'traditional-dance-video-classification/lib/keras_video/utils.py'\n",
            "removed 'traditional-dance-video-classification/lib/keras_video/__init__.py'\n",
            "removed 'traditional-dance-video-classification/lib/keras_video/flow.py'\n",
            "removed 'traditional-dance-video-classification/lib/keras_video/sliding.py'\n",
            "removed directory 'traditional-dance-video-classification/lib/keras_video'\n",
            "removed directory 'traditional-dance-video-classification/lib'\n",
            "removed 'traditional-dance-video-classification/.gitignore'\n",
            "removed 'traditional-dance-video-classification/notebooks/tari_i3d.ipynb'\n",
            "removed 'traditional-dance-video-classification/notebooks/tari_vgg16_lstm_224.ipynb'\n",
            "removed 'traditional-dance-video-classification/notebooks/i3d_inception.py'\n",
            "removed 'traditional-dance-video-classification/notebooks/tari_vgg16_lstm.ipynb'\n",
            "removed directory 'traditional-dance-video-classification/notebooks'\n",
            "removed 'traditional-dance-video-classification/checkpoint/.gitignore'\n",
            "removed directory 'traditional-dance-video-classification/checkpoint'\n",
            "removed 'traditional-dance-video-classification/dataset/.gitignore'\n",
            "removed directory 'traditional-dance-video-classification/dataset'\n",
            "removed directory 'traditional-dance-video-classification'\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rudyhendrawn/traditional-dance-video-classification.git\n",
        "!mv traditional-dance-video-classification/* .\n",
        "!rm -rfv traditional-dance-video-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f43fec4",
      "metadata": {
        "id": "3f43fec4"
      },
      "source": [
        "### Mounting Google Drive\n",
        "\n",
        "Google drive need to be setup and mounted to this specific project. Using this code below to setup and mount the google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b841342a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b841342a",
        "outputId": "fb6cf0e7-5e7d-41b4-f89a-8193eb8fd3a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bd7c8a6-0342-409d-b89d-717a94561372",
      "metadata": {
        "id": "1bd7c8a6-0342-409d-b89d-717a94561372"
      },
      "source": [
        "### Initial Setup ðŸ§‘â€ðŸ’»\n",
        "\n",
        "Setup the project, import the required dependencies\n",
        "\n",
        "> Make sure the `lib` directory exists and include: `keras_video`, `i3d_inception.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e7a88157-8cfc-4345-b025-f86c70862501",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:42:02.915397Z",
          "iopub.status.busy": "2022-07-25T16:42:02.914857Z",
          "iopub.status.idle": "2022-07-25T16:42:02.928720Z",
          "shell.execute_reply": "2022-07-25T16:42:02.926977Z",
          "shell.execute_reply.started": "2022-07-25T16:42:02.915356Z"
        },
        "id": "e7a88157-8cfc-4345-b025-f86c70862501"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import lib.helpers as helpers\n",
        "\n",
        "from lib.keras_video import VideoFrameGenerator\n",
        "from lib.i3d_inception import Inception_Inflated3d\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from IPython import get_ipython\n",
        "\n",
        "get_ipython().run_line_magic(\"matplotlib\", \"inline\")\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e0a9ce4c-5493-4810-a5d6-1fa48e3c2eaf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:04:20.487129Z",
          "iopub.status.busy": "2022-07-25T16:04:20.486515Z",
          "iopub.status.idle": "2022-07-25T16:04:20.493018Z",
          "shell.execute_reply": "2022-07-25T16:04:20.491404Z",
          "shell.execute_reply.started": "2022-07-25T16:04:20.487100Z"
        },
        "id": "e0a9ce4c-5493-4810-a5d6-1fa48e3c2eaf"
      },
      "outputs": [],
      "source": [
        "DS = os.path.sep\n",
        "DATASET_PATH = '/content/drive/MyDrive/Colab Notebooks/datasets/Tari-Bali' # Change with the correct path to your dataset\n",
        "\n",
        "# importing the zipfile module\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# loading the temp.zip and creating a zip object\n",
        "with ZipFile(os.path.join(DATASET_PATH, 'Dasar-Gerakan-Tari-Bali-All-Men.zip'), 'r') as zObject:\n",
        "    # Extracting all the members of the zip\n",
        "    # into a specific location.\n",
        "    zObject.extractall(path=os.path.join('/content'))\n",
        "\n",
        "# Read the video from specified path\n",
        "DATASET_DIR = os.path.join('/content/Dasar-Gerakan-Tari-Bali-All-Men')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce2e99ea-c85f-452f-a430-760f7ddc1cd8",
      "metadata": {
        "id": "ce2e99ea-c85f-452f-a430-760f7ddc1cd8"
      },
      "source": [
        "### Generating Class Names & Glob Pattern\n",
        "\n",
        "Load all the file paths at the DATASET_DIR to generate the class names. Also, define glob pattern to get the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "557993b1-841f-4e8f-9c9c-3401d778e7ac",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:04:22.904196Z",
          "iopub.status.busy": "2022-07-25T16:04:22.903859Z",
          "iopub.status.idle": "2022-07-25T16:04:22.910444Z",
          "shell.execute_reply": "2022-07-25T16:04:22.909092Z",
          "shell.execute_reply.started": "2022-07-25T16:04:22.904170Z"
        },
        "id": "557993b1-841f-4e8f-9c9c-3401d778e7ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d6d50a0-1f9e-4b86-81ae-590260e7e492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Agem_Kanan', 'Agem_Kiri', 'Gandang_Gandang', 'Malpal', 'Nayog', 'Nepuk_Kampuh', 'Oyod', 'Piles', 'Seledet', 'Tapak_Sirang_Pada', 'Ulap_Ulap']\n"
          ]
        }
      ],
      "source": [
        "class_names = helpers.get_generated_class_names(DATASET_DIR, \"train\")\n",
        "print(class_names)\n",
        "train_glob_pattern = helpers.get_generated_glob_pattern(DATASET_DIR, \"train\")\n",
        "test_glob_pattern = helpers.get_generated_glob_pattern(DATASET_DIR, \"test\");\n",
        "val_glob_pattern = helpers.get_generated_glob_pattern(DATASET_DIR, \"val\");"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0138dc52-4ea5-4e85-a317-fe9c26d6b529",
      "metadata": {
        "id": "0138dc52-4ea5-4e85-a317-fe9c26d6b529"
      },
      "source": [
        "### Dataset Setup\n",
        "\n",
        "Setup the dataset with `keras_video.VideoFrameGenerator` to do the dataset extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "514ec69c-b8dd-4941-9b39-29d1d1d34b89",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:04:26.901087Z",
          "iopub.status.busy": "2022-07-25T16:04:26.900666Z",
          "iopub.status.idle": "2022-07-25T16:04:26.918167Z",
          "shell.execute_reply": "2022-07-25T16:04:26.915995Z",
          "shell.execute_reply.started": "2022-07-25T16:04:26.901048Z"
        },
        "id": "514ec69c-b8dd-4941-9b39-29d1d1d34b89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f94756c8-fa7a-4b12-d7d1-b8cc3a051e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data: 11 classes for 531 files for train\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "NB_COLOR_CHANNELS = 3\n",
        "NB_FRAMES = 30\n",
        "RESOLUTION = (224, 224)\n",
        "\n",
        "train_dataset_generator = VideoFrameGenerator(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    classes=class_names,\n",
        "    glob_pattern=train_glob_pattern,\n",
        "    nb_channel=NB_COLOR_CHANNELS,\n",
        "    nb_frames=NB_FRAMES,\n",
        "    seed=42,\n",
        "    target_shape=RESOLUTION,\n",
        "    transformation=None,\n",
        "    use_frame_cache=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bb4fd813",
      "metadata": {
        "id": "bb4fd813",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca3f251-3c44-4727-a11d-d72e92fc7758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data: 11 classes for 165 files for train\n"
          ]
        }
      ],
      "source": [
        "test_dataset_generator = VideoFrameGenerator(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    classes=class_names,\n",
        "    glob_pattern=test_glob_pattern,\n",
        "    nb_channel=NB_COLOR_CHANNELS,\n",
        "    nb_frames=NB_FRAMES,\n",
        "    seed=42,\n",
        "    target_shape=RESOLUTION,\n",
        "    transformation=None,\n",
        "    use_frame_cache=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e9eabb8b",
      "metadata": {
        "id": "e9eabb8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66aae808-8208-401e-eb79-c4d24c8f9fda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total data: 11 classes for 132 files for train\n"
          ]
        }
      ],
      "source": [
        "val_dataset_generator = VideoFrameGenerator(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    classes=class_names,\n",
        "    glob_pattern=val_glob_pattern,\n",
        "    nb_channel=NB_COLOR_CHANNELS,\n",
        "    nb_frames=NB_FRAMES,\n",
        "    seed=42,\n",
        "    target_shape=RESOLUTION,\n",
        "    transformation=None,\n",
        "    use_frame_cache=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in train_dataset_generator:\n",
        "    print(f\"Data shape in data generator {x.shape}\")\n",
        "    break\n",
        "\n",
        "for x, y in val_dataset_generator:\n",
        "    print(f\"Data shape in data generator {x.shape}\")\n",
        "    break\n",
        "\n",
        "for x, y in test_dataset_generator:\n",
        "    print(f\"Data shape in data generator {x.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "9CipAiqIu7Ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea64ef0f-9f6a-4cc2-ff55-d6f9263cd291"
      },
      "id": "9CipAiqIu7Ot",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape in data generator (8, 30, 224, 224, 3)\n",
            "Data shape in data generator (8, 30, 224, 224, 3)\n",
            "Data shape in data generator (8, 30, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3a3a7b36",
      "metadata": {
        "id": "3a3a7b36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6675df50-b2ba-458f-9a4d-bfeb6150c840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "input_shape = (NB_FRAMES,) + RESOLUTION + (NB_COLOR_CHANNELS,)\n",
        "print(input_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f4555eb-20c8-475c-94e3-20539a364bfa",
      "metadata": {
        "id": "0f4555eb-20c8-475c-94e3-20539a364bfa"
      },
      "source": [
        "### Prepare `i3d` Layer\n",
        "\n",
        "Preparing the configuration to create the `i3d` layer to add to the created model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "74bd9216-641b-41b4-829f-10d8a14060e0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:04:32.073646Z",
          "iopub.status.busy": "2022-07-25T16:04:32.073178Z",
          "iopub.status.idle": "2022-07-25T16:04:35.135165Z",
          "shell.execute_reply": "2022-07-25T16:04:35.133988Z",
          "shell.execute_reply.started": "2022-07-25T16:04:32.073602Z"
        },
        "id": "74bd9216-641b-41b4-829f-10d8a14060e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dcd068d-1e66-4359-f933-92ec27b1fa48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/dlpbc/keras-kinetics-i3d/releases/download/v0.2/rgb_inception_i3d_kinetics_only_tf_dim_ordering_tf_kernels_no_top.h5\n",
            "49595336/49595336 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "i3d_layer = Inception_Inflated3d(\n",
        "    classes=3,\n",
        "    include_top=False,\n",
        "    input_shape=input_shape,\n",
        "    weights=\"rgb_kinetics_only\"\n",
        ")\n",
        "\n",
        "i3d_layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11cd363f-ac76-4ce1-a56a-4e46a8ac9ab4",
      "metadata": {
        "id": "11cd363f-ac76-4ce1-a56a-4e46a8ac9ab4"
      },
      "source": [
        "### Model Creation\n",
        "\n",
        "Creating `Sequential` model and add `i3d` and some other layers to the created model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8f80d370-8f03-4c41-a24f-e1a95a6413c7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:04:39.065422Z",
          "iopub.status.busy": "2022-07-25T16:04:39.064911Z",
          "iopub.status.idle": "2022-07-25T16:04:39.674862Z",
          "shell.execute_reply": "2022-07-25T16:04:39.673428Z",
          "shell.execute_reply.started": "2022-07-25T16:04:39.065391Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f80d370-8f03-4c41-a24f-e1a95a6413c7",
        "outputId": "0705147e-7aa1-42a9-b0cc-e8f2f9cf2d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " i3d_inception (Functional)  (None, 3, 1, 1, 1024)     12294544  \n",
            "                                                                 \n",
            " global_average_pooling3d (G  (None, 1024)             0         \n",
            " lobalAveragePooling3D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 11)                5643      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,824,987\n",
            "Trainable params: 530,443\n",
            "Non-trainable params: 12,294,544\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# classification layer\n",
        "model.add(i3d_layer)\n",
        "model.add(tf.keras.layers.GlobalAveragePooling3D())\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(int(len(class_names)), activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dcc6aee-aa61-4805-8b5a-65f76a78a707",
      "metadata": {
        "id": "6dcc6aee-aa61-4805-8b5a-65f76a78a707"
      },
      "source": [
        "### Compiling & Fitting Setup\n",
        "\n",
        "Some setup configuration for compiling and fitting the model. Defining epochs, earlystopping, checkpoint, and callbacks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6f6b887f-126c-479e-849a-3d3669cfe8f7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:04:55.745142Z",
          "iopub.status.busy": "2022-07-25T16:04:55.744633Z",
          "iopub.status.idle": "2022-07-25T16:04:55.753861Z",
          "shell.execute_reply": "2022-07-25T16:04:55.751542Z",
          "shell.execute_reply.started": "2022-07-25T16:04:55.745099Z"
        },
        "id": "6f6b887f-126c-479e-849a-3d3669cfe8f7"
      },
      "outputs": [],
      "source": [
        "epochs = 3\n",
        "model_earlystopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"checkpoint/i3d-{epoch:02d}-{val_loss:.2f}.h5\",\n",
        "    mode=\"min\",\n",
        "    monitor=\"val_loss\",\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model_callbacks = [model_earlystopping, model_checkpoint]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adafba19-c904-4376-9f27-79d85cf5460e",
      "metadata": {
        "id": "adafba19-c904-4376-9f27-79d85cf5460e"
      },
      "source": [
        "### Model Compile\n",
        "\n",
        "Compiling model with pre-defined configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c1f1a83a-b643-41fb-9e7d-be2c518b514c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:04:59.144203Z",
          "iopub.status.busy": "2022-07-25T16:04:59.143709Z",
          "iopub.status.idle": "2022-07-25T16:04:59.168565Z",
          "shell.execute_reply": "2022-07-25T16:04:59.166968Z",
          "shell.execute_reply.started": "2022-07-25T16:04:59.144178Z"
        },
        "id": "c1f1a83a-b643-41fb-9e7d-be2c518b514c"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"acc\"],\n",
        "    optimizer=\"adam\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a34c8472-3564-4429-84d4-48ab13632755",
      "metadata": {
        "id": "a34c8472-3564-4429-84d4-48ab13632755"
      },
      "source": [
        "### Model Training/Fitting\n",
        "\n",
        "Fit the model with real dataset with defined epochs and callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b9cb3ff0-b811-4032-bf25-332ac5d03e2c",
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-07-25T16:05:04.707915Z",
          "iopub.status.busy": "2022-07-25T16:05:04.707476Z",
          "iopub.status.idle": "2022-07-25T16:09:57.723320Z",
          "shell.execute_reply": "2022-07-25T16:09:57.721357Z",
          "shell.execute_reply.started": "2022-07-25T16:05:04.707887Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9cb3ff0-b811-4032-bf25-332ac5d03e2c",
        "outputId": "c16245f8-9bfb-4211-c7f2-0cd6e6746f26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "66/66 [==============================] - ETA: 0s - loss: 2.4475 - acc: 0.1591\n",
            "Epoch 1: val_loss improved from inf to 2.16803, saving model to checkpoint/i3d-01-2.17.h5\n",
            "66/66 [==============================] - 179s 3s/step - loss: 2.4475 - acc: 0.1591 - val_loss: 2.1680 - val_acc: 0.2344\n",
            "Epoch 2/3\n",
            "66/66 [==============================] - ETA: 0s - loss: 2.1174 - acc: 0.2519\n",
            "Epoch 2: val_loss improved from 2.16803 to 2.07173, saving model to checkpoint/i3d-02-2.07.h5\n",
            "66/66 [==============================] - 165s 2s/step - loss: 2.1174 - acc: 0.2519 - val_loss: 2.0717 - val_acc: 0.1953\n",
            "Epoch 3/3\n",
            "66/66 [==============================] - ETA: 0s - loss: 2.0757 - acc: 0.2481\n",
            "Epoch 3: val_loss improved from 2.07173 to 1.97965, saving model to checkpoint/i3d-03-1.98.h5\n",
            "66/66 [==============================] - 179s 3s/step - loss: 2.0757 - acc: 0.2481 - val_loss: 1.9797 - val_acc: 0.2109\n",
            "Fitting execution time : 524.8913578987122s\n"
          ]
        }
      ],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "model_history = model.fit(\n",
        "    train_dataset_generator,\n",
        "    callbacks=model_callbacks,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_dataset_generator\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "exec_time = end_time - start_time\n",
        "\n",
        "print(\"Fitting execution time : {}s\".format(exec_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e9d822e-33b9-4429-8169-56ceb8ce7dbd",
      "metadata": {
        "id": "7e9d822e-33b9-4429-8169-56ceb8ce7dbd"
      },
      "source": [
        "### Save Model\n",
        "\n",
        "Saving model file into `model` directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bb765ef-5c9b-4368-b17f-633083db5dec",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:11:54.464547Z",
          "iopub.status.busy": "2022-07-25T16:11:54.464192Z",
          "iopub.status.idle": "2022-07-25T16:11:55.305480Z",
          "shell.execute_reply": "2022-07-25T16:11:55.304298Z",
          "shell.execute_reply.started": "2022-07-25T16:11:54.464520Z"
        },
        "id": "7bb765ef-5c9b-4368-b17f-633083db5dec"
      },
      "outputs": [],
      "source": [
        "# model.save(\"model/dance/i3d-5e.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39addeb6-7efe-43c6-b38b-fc0b8f23e865",
      "metadata": {
        "id": "39addeb6-7efe-43c6-b38b-fc0b8f23e865"
      },
      "source": [
        "### Acc Visualization\n",
        "\n",
        "Visualizing acc data with Matplotlib graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a6760a-3feb-4380-9f68-917e786ccb5d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:14:03.616288Z",
          "iopub.status.busy": "2022-07-25T16:14:03.615660Z",
          "iopub.status.idle": "2022-07-25T16:14:03.858974Z",
          "shell.execute_reply": "2022-07-25T16:14:03.857863Z",
          "shell.execute_reply.started": "2022-07-25T16:14:03.616226Z"
        },
        "id": "c2a6760a-3feb-4380-9f68-917e786ccb5d"
      },
      "outputs": [],
      "source": [
        "helpers.get_visualized_graph(\n",
        "  plots=[model_history.history[\"acc\"], model_history.history[\"val_acc\"]],\n",
        "  title=\"Model Accuracy\",\n",
        "  x_label=\"Epoch\",\n",
        "  y_label=\"Accuracy\",\n",
        "  legend=[\"train\", \"test\"]\n",
        ").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "641f828d-52a6-4be1-bf9a-81dddfac9cd1",
      "metadata": {
        "id": "641f828d-52a6-4be1-bf9a-81dddfac9cd1"
      },
      "source": [
        "### Loss Visualization\n",
        "\n",
        "Visualizing loss data with Matplotlib graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d602ed61-58b0-44a8-b781-b5db0c04f5e7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:16:04.228008Z",
          "iopub.status.busy": "2022-07-25T16:16:04.227507Z",
          "iopub.status.idle": "2022-07-25T16:16:04.444393Z",
          "shell.execute_reply": "2022-07-25T16:16:04.442975Z",
          "shell.execute_reply.started": "2022-07-25T16:16:04.227962Z"
        },
        "id": "d602ed61-58b0-44a8-b781-b5db0c04f5e7"
      },
      "outputs": [],
      "source": [
        "helpers.get_visualized_graph(\n",
        "  plots=[model_history.history[\"loss\"], model_history.history[\"val_loss\"]],\n",
        "  title=\"Model Loss\",\n",
        "  x_label=\"Epoch\",\n",
        "  y_label=\"Loss\",\n",
        "  legend=[\"train\", \"test\"]\n",
        ").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "482d50ed-f966-42f9-a407-3fe05d6a1455",
      "metadata": {
        "id": "482d50ed-f966-42f9-a407-3fe05d6a1455"
      },
      "source": [
        "### Export Dataframe From Model\n",
        "\n",
        "Export dataframe to `.csv` file from the model history via Pandas library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f293766d-342f-402d-b949-de7108a2cabd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:19:39.293201Z",
          "iopub.status.busy": "2022-07-25T16:19:39.292738Z",
          "iopub.status.idle": "2022-07-25T16:19:39.311552Z",
          "shell.execute_reply": "2022-07-25T16:19:39.310234Z",
          "shell.execute_reply.started": "2022-07-25T16:19:39.293173Z"
        },
        "id": "f293766d-342f-402d-b949-de7108a2cabd"
      },
      "outputs": [],
      "source": [
        "model_history_dataframe = pd.DataFrame(model_history.history)\n",
        "model_history_fpath = \"history/dance/i3d-5e.csv\"\n",
        "\n",
        "with open(model_history_fpath, mode=\"w\") as history_file:\n",
        "    model_history_dataframe.to_csv(history_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6842666-03a7-44db-b30a-d21b5983510e",
      "metadata": {
        "id": "b6842666-03a7-44db-b30a-d21b5983510e"
      },
      "source": [
        "### Model Evaluation\n",
        "\n",
        "Evaluating model with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d769e89a-dd06-428a-8632-ad95adc55111",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:20:25.650916Z",
          "iopub.status.busy": "2022-07-25T16:20:25.650350Z",
          "iopub.status.idle": "2022-07-25T16:20:36.319566Z",
          "shell.execute_reply": "2022-07-25T16:20:36.318725Z",
          "shell.execute_reply.started": "2022-07-25T16:20:25.650863Z"
        },
        "id": "d769e89a-dd06-428a-8632-ad95adc55111"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_dataset_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e85e757-d57d-4dbd-8945-593c3e72b615",
      "metadata": {
        "id": "2e85e757-d57d-4dbd-8945-593c3e72b615"
      },
      "source": [
        "### Populate Y Data\n",
        "\n",
        "Populating Y's `prediction` and `test` data with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fd9ea56-712e-4aa6-9df6-e45e2a4aa672",
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-07-25T16:23:42.063471Z",
          "iopub.status.busy": "2022-07-25T16:23:42.062191Z",
          "iopub.status.idle": "2022-07-25T16:24:04.327613Z",
          "shell.execute_reply": "2022-07-25T16:24:04.326316Z",
          "shell.execute_reply.started": "2022-07-25T16:23:42.063442Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "7fd9ea56-712e-4aa6-9df6-e45e2a4aa672"
      },
      "outputs": [],
      "source": [
        "y_prediction_max, y_true = helpers.get_populated_y_data(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    generator=test_dataset_generator,\n",
        "    model=model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "883998d3-0340-4b76-8cfe-30681ead035c",
      "metadata": {
        "id": "883998d3-0340-4b76-8cfe-30681ead035c"
      },
      "source": [
        "### Score Visualization\n",
        "\n",
        "Visualizing some of calculated model score types, like `accuracy`, `precision`, `recall`, and `f1` score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b3af71-d7ab-43fd-9e30-dfeb520496a8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:32:34.810618Z",
          "iopub.status.busy": "2022-07-25T16:32:34.810167Z",
          "iopub.status.idle": "2022-07-25T16:32:34.825602Z",
          "shell.execute_reply": "2022-07-25T16:32:34.824524Z",
          "shell.execute_reply.started": "2022-07-25T16:32:34.810589Z"
        },
        "id": "e1b3af71-d7ab-43fd-9e30-dfeb520496a8"
      },
      "outputs": [],
      "source": [
        "score_accuracy, score_precision, score_recall, score_f1 = helpers.get_calculated_score(y_true, y_prediction_max)\n",
        "\n",
        "print(f\"Accuracy Score\\t: {np.round(score_accuracy, 3)}\")\n",
        "print(f\"Precision Score\\t: {np.round(score_precision, 3)}\")\n",
        "print(f\"Recall Score\\t: {np.round(score_recall, 3)}\")\n",
        "print(f\"F1 Score\\t: {np.round(score_f1, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fa689bf-dea3-4a90-a241-bfda48c409a6",
      "metadata": {
        "id": "5fa689bf-dea3-4a90-a241-bfda48c409a6"
      },
      "source": [
        "### Classification Report Visualization\n",
        "\n",
        "Visualizing classification report of test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d74073ca-1213-46b5-aa55-5ff9b6050762",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:34:10.058994Z",
          "iopub.status.busy": "2022-07-25T16:34:10.058550Z",
          "iopub.status.idle": "2022-07-25T16:34:10.075212Z",
          "shell.execute_reply": "2022-07-25T16:34:10.073843Z",
          "shell.execute_reply.started": "2022-07-25T16:34:10.058966Z"
        },
        "id": "d74073ca-1213-46b5-aa55-5ff9b6050762"
      },
      "outputs": [],
      "source": [
        "test_class_names = test_dataset_generator.classes\n",
        "\n",
        "print(classification_report(\n",
        "    y_true,\n",
        "    y_prediction_max,\n",
        "    target_names=test_class_names\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88c52bbb-ea6e-47b9-b32a-27458e5792b0",
      "metadata": {
        "id": "88c52bbb-ea6e-47b9-b32a-27458e5792b0"
      },
      "source": [
        "### Confusion Matrix Visualization\n",
        "\n",
        "Visualizing confusion matrix with heatmap table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6933551-5212-4480-9adb-20ba8965ea68",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:36:30.051192Z",
          "iopub.status.busy": "2022-07-25T16:36:30.050712Z",
          "iopub.status.idle": "2022-07-25T16:36:30.288844Z",
          "shell.execute_reply": "2022-07-25T16:36:30.287387Z",
          "shell.execute_reply.started": "2022-07-25T16:36:30.051155Z"
        },
        "id": "e6933551-5212-4480-9adb-20ba8965ea68"
      },
      "outputs": [],
      "source": [
        "confusion_matrix_result = confusion_matrix(y_true, y_prediction_max)\n",
        "\n",
        "sns.heatmap(\n",
        "    confusion_matrix_result,\n",
        "    annot=True,\n",
        "    cmap=\"Blues\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3cc50ab-f69f-4ba5-b1af-375c95a56c9a",
      "metadata": {
        "id": "e3cc50ab-f69f-4ba5-b1af-375c95a56c9a"
      },
      "source": [
        "### AUC Score Visualization\n",
        "\n",
        "Visualization of AUC score calculated with FPR and TPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3af434f-88f2-4edc-8f06-3701ef724c92",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:42:07.324427Z",
          "iopub.status.busy": "2022-07-25T16:42:07.323141Z",
          "iopub.status.idle": "2022-07-25T16:42:07.333830Z",
          "shell.execute_reply": "2022-07-25T16:42:07.332238Z",
          "shell.execute_reply.started": "2022-07-25T16:42:07.324398Z"
        },
        "id": "f3af434f-88f2-4edc-8f06-3701ef724c92"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, _ = roc_curve(y_true, y_prediction_max, pos_label=6)\n",
        "score_auc = auc(fpr, tpr)\n",
        "\n",
        "print(f\"AUC Score\\t: {np.round(score_auc, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67e6fb24-3c5c-4a63-92dd-125159d877db",
      "metadata": {
        "id": "67e6fb24-3c5c-4a63-92dd-125159d877db"
      },
      "source": [
        "### True/False Positive Rate Visualization\n",
        "\n",
        "Visualizing `true`/`false` rate with Matplotlib graph calculated from FPR and TPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "380dd9ed-0ff2-4d41-9eba-c690760bbac7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T16:44:26.564209Z",
          "iopub.status.busy": "2022-07-25T16:44:26.563801Z",
          "iopub.status.idle": "2022-07-25T16:44:26.717569Z",
          "shell.execute_reply": "2022-07-25T16:44:26.716189Z",
          "shell.execute_reply.started": "2022-07-25T16:44:26.564181Z"
        },
        "id": "380dd9ed-0ff2-4d41-9eba-c690760bbac7"
      },
      "outputs": [],
      "source": [
        "plt.plot(fpr, tpr, marker=\".\")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccc9006e-33e9-4690-8563-cbe7bb4402d6",
      "metadata": {
        "id": "ccc9006e-33e9-4690-8563-cbe7bb4402d6"
      },
      "source": [
        "### Visualizing Checkpoint Model\n",
        "\n",
        "Visualizing all the score/calculated score from the checkpoint model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7048aed-08d2-403a-b9ee-7d8cbfc7fd6f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T17:03:00.315146Z",
          "iopub.status.busy": "2022-07-25T17:03:00.314759Z",
          "iopub.status.idle": "2022-07-25T17:03:14.232305Z",
          "shell.execute_reply": "2022-07-25T17:03:14.230697Z",
          "shell.execute_reply.started": "2022-07-25T17:03:00.315119Z"
        },
        "id": "f7048aed-08d2-403a-b9ee-7d8cbfc7fd6f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "checkpoint_model = load_model(\"checkpoint/i3d.h5\")\n",
        "checkpoint_model.evaluate(test_dataset_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4feea24-7170-43ba-8225-c8b58b654453",
      "metadata": {
        "id": "f4feea24-7170-43ba-8225-c8b58b654453"
      },
      "source": [
        "### Populate Y Data\n",
        "\n",
        "Populating checkpoint model Y's `prediction` and `test` data with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "344e94b8-84fb-479a-b317-0dfb05c822cb",
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2022-07-25T17:04:21.347485Z",
          "iopub.status.busy": "2022-07-25T17:04:21.346243Z",
          "iopub.status.idle": "2022-07-25T17:04:43.023798Z",
          "shell.execute_reply": "2022-07-25T17:04:43.022571Z",
          "shell.execute_reply.started": "2022-07-25T17:04:21.347454Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "344e94b8-84fb-479a-b317-0dfb05c822cb"
      },
      "outputs": [],
      "source": [
        "y_prediction_max, y_true = helpers.get_populated_y_data(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    generator=test_dataset_generator,\n",
        "    model=model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d143f10-70a6-43e6-8fae-941be3a3e9ca",
      "metadata": {
        "id": "4d143f10-70a6-43e6-8fae-941be3a3e9ca"
      },
      "source": [
        "### Score Visualization\n",
        "\n",
        "Visualizing some of calculated checkpoint model score types, like `accuracy`, `precision`, `recall`, and `f1` score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e04816e7-15b5-4517-b2fe-2a40b130160d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T17:05:27.821439Z",
          "iopub.status.busy": "2022-07-25T17:05:27.820933Z",
          "iopub.status.idle": "2022-07-25T17:05:27.840382Z",
          "shell.execute_reply": "2022-07-25T17:05:27.839165Z",
          "shell.execute_reply.started": "2022-07-25T17:05:27.821396Z"
        },
        "id": "e04816e7-15b5-4517-b2fe-2a40b130160d"
      },
      "outputs": [],
      "source": [
        "score_accuracy, score_precision, score_recall, score_f1 = helpers.get_calculated_score(y_true, y_prediction_max)\n",
        "\n",
        "print(f\"Accuracy Score\\t: {np.round(score_accuracy, 3)}\")\n",
        "print(f\"Precision Score\\t: {np.round(score_precision, 3)}\")\n",
        "print(f\"Recall Score\\t: {np.round(score_recall, 3)}\")\n",
        "print(f\"F1 Score\\t: {np.round(score_f1, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0da6f90d-1d19-4539-a05f-2de57dd9fd29",
      "metadata": {
        "id": "0da6f90d-1d19-4539-a05f-2de57dd9fd29"
      },
      "source": [
        "### Classification Report Visualization\n",
        "\n",
        "Visualizing checkpoint model classification report of test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e1229da-8e7a-4e57-8d64-2c600a9db03c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T17:06:30.463125Z",
          "iopub.status.busy": "2022-07-25T17:06:30.461724Z",
          "iopub.status.idle": "2022-07-25T17:06:30.477437Z",
          "shell.execute_reply": "2022-07-25T17:06:30.475890Z",
          "shell.execute_reply.started": "2022-07-25T17:06:30.463020Z"
        },
        "id": "2e1229da-8e7a-4e57-8d64-2c600a9db03c"
      },
      "outputs": [],
      "source": [
        "test_class_names = test_dataset_generator.classes\n",
        "\n",
        "print(classification_report(\n",
        "    y_true,\n",
        "    y_prediction_max,\n",
        "    target_names=test_class_names\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ef84fa1-9e1a-40af-bd73-e5eab70e8f72",
      "metadata": {
        "id": "2ef84fa1-9e1a-40af-bd73-e5eab70e8f72"
      },
      "source": [
        "### Confusion Matrix Visualization\n",
        "\n",
        "Visualizing checkpoint model confusion matrix with heatmap table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a388bd6-5bd9-43e6-8e5e-a2e6b273fb5b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T17:08:11.189079Z",
          "iopub.status.busy": "2022-07-25T17:08:11.188646Z",
          "iopub.status.idle": "2022-07-25T17:08:11.451053Z",
          "shell.execute_reply": "2022-07-25T17:08:11.450105Z",
          "shell.execute_reply.started": "2022-07-25T17:08:11.189050Z"
        },
        "id": "4a388bd6-5bd9-43e6-8e5e-a2e6b273fb5b"
      },
      "outputs": [],
      "source": [
        "confusion_matrix_result = confusion_matrix(y_true, y_prediction_max)\n",
        "\n",
        "sns.heatmap(\n",
        "    confusion_matrix_result,\n",
        "    annot=True,\n",
        "    cmap=\"Blues\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "231a5d94-09d9-4db2-a676-0ee3d43c0219",
      "metadata": {
        "id": "231a5d94-09d9-4db2-a676-0ee3d43c0219"
      },
      "source": [
        "### AUC Score Visualization\n",
        "\n",
        "Visualization of checkpoint model AUC score calculated with FPR and TPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16b59826-8b3b-47fe-b5b3-ff78387a96f3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T17:09:41.872413Z",
          "iopub.status.busy": "2022-07-25T17:09:41.872022Z",
          "iopub.status.idle": "2022-07-25T17:09:41.881420Z",
          "shell.execute_reply": "2022-07-25T17:09:41.879771Z",
          "shell.execute_reply.started": "2022-07-25T17:09:41.872386Z"
        },
        "id": "16b59826-8b3b-47fe-b5b3-ff78387a96f3"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, _ = roc_curve(y_true, y_prediction_max, pos_label=6)\n",
        "score_auc = auc(fpr, tpr)\n",
        "\n",
        "print(f\"AUC Score\\t: {np.round(score_auc, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "486f4586-8fdb-4557-bf9a-ddc855709e83",
      "metadata": {
        "id": "486f4586-8fdb-4557-bf9a-ddc855709e83"
      },
      "source": [
        "### True/False Positive Rate Visualization\n",
        "\n",
        "Visualizing checkpoint model `true`/`false` rate with Matplotlib graph calculated from FPR and TPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4325b853-4201-4fe5-9259-8bdbbfc85e21",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-07-25T17:11:04.016162Z",
          "iopub.status.busy": "2022-07-25T17:11:04.014523Z",
          "iopub.status.idle": "2022-07-25T17:11:04.203854Z",
          "shell.execute_reply": "2022-07-25T17:11:04.202661Z",
          "shell.execute_reply.started": "2022-07-25T17:11:04.016111Z"
        },
        "id": "4325b853-4201-4fe5-9259-8bdbbfc85e21"
      },
      "outputs": [],
      "source": [
        "plt.plot(fpr, tpr, marker=\".\")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}